{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Components\n",
    "\n",
    "## GloVe\n",
    "\n",
    "GloVe is a method for finding word representations within the structure of the whole observed corpus of data. GloVe accomplishes this by minimizing the least-squares error of a function which contains information about the global co-occurrences of words (the frequency with which two words appear in the same context) as well as a weighting function for each separate co-occurrence <span data-cite=\"pennington2014glove\">(Pennington, Socher, & Manning, 2014)</span>.\n",
    "\n",
    "## Gated Recurrent Unit (GRU)\n",
    "\n",
    "Gated Recurrent Units (GRUs) are a type of recurrent neural network (RNN) that incorporates a gating mechanism to manage long-term dependencies in sequence models <span data-cite=\"cho2014gru\">(Cho et al., 2014)</span>. They were originally designed as a simplification on the Long Short-Term Memory (LSTM) models. The original (fully gated) version of this model is parameterized as follows, starting from $t=0$ and $h_0=0$.\n",
    "\\begin{align}\n",
    "    \\mathbf{z}_t &= \\sigma(\\mathbf{W}_z\\mathbf{x}_t + \\mathbf{U}_z\\mathbf{h}_{t-1} + \\mathbf{b}_z) \\\\\n",
    "    \\mathbf{r}_t &= \\sigma(\\mathbf{W}_r\\mathbf{x}_t + \\mathbf{U}_r\\mathbf{h}_{t-1} + \\mathbf{b}_r) \\\\\n",
    "    \\mathbf{h}_t &= (1-\\mathbf{z}_t)\\cdot\\mathbf{h}_{t-1} + \\mathbf{z}_t\\cdot\\mathrm{tanh}(\\mathbf{W}_h\\mathbf{x}_t + \\mathbf{U}_h(\\mathbf{r}_t\\cdot\\mathbf{h}_{t-1}) + \\mathbf{b}_h)\n",
    "\\end{align}\n",
    "where $\\mathbf{x}_t$ is the input vector, $\\mathbf{h}_t$ is the output vector, $\\mathbf{z}_t$ is the output of the update gate, $\\mathbf{r}_t$ is the output of the reset gate, $\\sigma$ is the sigmoid non-linearity, $\\mathrm{tanh}$ is the hyperbolic tangent non-linearity, and $\\mathbf{W}$, $\\mathbf{U}$ and $\\mathbf{b}$ are parameter matrices and biases of the output ($\\mathbf{h}$), reset ($\\mathbf{r}$), and update gates ($\\mathbf{z}$).\n",
    "\n",
    "## SMOTE\n",
    "\n",
    "SMOTE is a synthetic minority over-sampling technique. Normal over-sampling techniques (such as those used in 'ROC Convex Hull methods') which uses minority over-sampling with replacement from the original data does not perform better than under-sampling the majority. In SMOTE, the authors propose a new technique of over-sampling by creating 'synthetic' examples rather than by over-sampling with replacement.\n",
    "\n",
    "## Stacked Model\n",
    "\n",
    "A Stacked model incorporates more than one structural level of data such that the processing of lower levels informs later levels compositionally. Stacked models are differentiated from regular hierarchical models (e.g., a multilayer perceptron) by defining a different, *a priori* semantics over each structural level. For example, a simple Stacked model produces an embedding for a single session's tokens first, then produces an embedding for a single venture based on an ordered set of session token embeddings.\n",
    "\n",
    "## Tokenization\n",
    "\n",
    "Preprocessing and tokenization are important elements in the natural language processing pipeline. To our knowledge, there do not exist any end-to-end preprocessing and tokenization solutions that meet our current requirements. As a consequence, we have built a custom preprocessing pipeline on the basis of existing solutions. The current steps in order are as follows:\n",
    "\n",
    "\n",
    "1. Character-level clean up (e.g., remove non-ASCII, lowercase).\n",
    "2. Word-level clean up and punctuation (e.g., remove contractions, lemmatize).\n",
    "3. Replace words with integer keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
